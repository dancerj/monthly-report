%; whizzy chapter
% -initex iniptex -latex platex -format platex -bibtex jbibtex -fmt fmt
% 以上 whizzytex を使用する場合の設定。


%     Tokyo Debian Meeting resources
%     Copyright (C) 2010 Junichi Uekawa

%     This program is free software; you can redistribute it and/or modify
%     it under the terms of the GNU General Public License as published by
%     the Free Software Foundation; either version 2 of the License, or
%     (at your option) any later version.

%     This program is distributed in the hope that it will be useful,
%     but WITHOUT ANY WARRANTY; without even the implied warranty of
%     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%     GNU General Public License for more details.

%     You should have received a copy of the GNU General Public License
%     along with this program; if not, write to the Free Software
%     Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA

%  preview (shell-command (concat "evince " (replace-regexp-in-string "tex$" "pdf"(buffer-file-name)) "&"))
% 画像ファイルを処理するためにはebbを利用してboundingboxを作成。
%(shell-command "cd image201002; ebb *.png")

%%ここからヘッダ開始。

\documentclass[mingoth,a4paper]{jsarticle}
\usepackage{monthlyreport}
\usepackage{wrapfig}

% 日付を定義する、毎月変わります。
\newcommand{\debmtgyear}{2010}
\newcommand{\debmtgmonth}{2}
\newcommand{\debmtgdate}{20,21}
\newcommand{\debmtgnumber}{61}

\begin{document}

\begin{titlepage}
\thispagestyle{empty}

% タイトルページ:編集必要な部分は最初のマクロに飛ばすこと

\vspace*{-2cm}
第\debmtgnumber{}回 東京エリア Debian 勉強会資料

\hspace*{-2.4cm}
\includegraphics[width=210mm]{image200801/2008title.eps}\\
\hfill{}\debmtgyear{}年\debmtgmonth{}月\debmtgdate{}日

\end{titlepage}


\dancersection{Introduction}{上川 純一}

\begin{multicols}{2}
 
 
 今月のDebian勉強会へようこそ。これからDebianの世界にあしを踏み入れると
 いう方も、すでにどっぷりとつかっているという方も、月に一回Debianについ
 て語りませんか？

 Debian勉強会の目的は下記です。

 \begin{itemize}
 \item \underline{Debian Developer} (開発者)の育成。
 \item 日本語での「\underline{開発に関する情報}」を整理してまとめ、アップデートする。
 \item \underline{場}の提供。
 \begin{itemize}
  \item 普段ばらばらな場所にいる人々が face-to-face で出会える場を提供
	する。
  \item Debian のためになることを語る場を提供する。
  \item Debianについて語る場を提供する。
 \end{itemize}
 \end{itemize}		

 Debianの勉強会ということで究極的には参加者全員がDebian Packageをがりがり
 と作るスーパーハッカーになった姿を妄想しています。情報の共有・活用を通し
 て Debianの今後の能動的な展開への土台として、「場」としての空間を提供す
 るのが目的です。

\end{multicols}

\newpage

\begin{minipage}[b]{0.2\hsize}
 \definecolor{titleback}{gray}{0.9}
 \colorbox{titleback}{\rotatebox{90}{\fontsize{80}{80} {\gt デビアン勉強会} }}
\end{minipage}
\begin{minipage}[b]{0.8\hsize}
\hrule
\vspace{2mm}
\hrule
\tableofcontents
\vspace{2mm}
\hrule
\end{minipage}

\dancersection{事前課題}{上川 純一}

今回の事前課題は以下です:

\begin{enumerate}
 \item 事前課題の内容
\end{enumerate}

この課題に対して提出いただいた内容は以下です。

\input{image201002/prework.tex}

\dancersection{最近のDebian関連のミーティング報告}{上川純一}
\subsection{東京エリアDebian勉強会60回目報告}
% (query-replace-regexp "<.*?>" "")
% (query-replace-regexp "^[	 ]\+" "")

前回の BSP の開催報告

% =======================================================================
\dancersection{Debian の紹介}{やまねひでき}
\index{why debian}
% =======================================================================

\subsection{Debian とは何か}
「Debian とは一体何ですか? (\url{http://www.debian.org/intro/about})」
には以下のように書かれています。

\begin{description}
\item \small Debian Project は、フリーなオペレーティングシステムを作成するために連携した
個人の集団です。 我々が作成したこのオペレーティングシステムは Debian GNU/Linux 
もしくはもっと短かく簡単に Debian と呼ばれています。
\end{description}



\subsection{Debian の特徴}
今だと Windows/MacOSX 以外の「いわゆるフリーなOS」はいくつかあります。
では、他の OS / ディストリビューションと Debian の違い、その特徴を語る
キーワードとは何でしょうか？私は「Universal OS」「フリー」「ボランティア」
の三つを挙げます。順を追って説明します。


\subsubsection{Universal OS}
これが Debian が目指すものです。その意味するところは
「あらゆるマシンで動くフリーなソフトウェアによる誰もが使えるOS」です。
単に PC で動くだけではなく、最近は廃れてきましたが UNIX ワークステーションや
汎用機、組み込み用機器、モバイル端末、ゲーム機…あらゆるマシンで動作すること
を目指しています。そのため多数の CPU アーキテクチャをサポートしているのが
特徴です。サポートする／した／しようとしているアーキテクチャは以下があります。

\begin{itemize}
 \item i386	（通常の PC）
 \item amd64	（最近の 64bit CPU）
 \item ia64	（流行らない Intel の64bit CPU。Itanium など）
 \item mips/mipsel
 \item arm/armel（シャープの Netwalker やモバイル端末がこれ）
 \item alpha
 \item hppa	（HP のワークステーション）
 \item sparc	（Sun）
 \item powerpc
 \item m68k	（昔の Macintosh や Amiga など）
 \item s390 	（汎用機です）
 \item sh	（日立の）
 \item avr32
\end{itemize}

また、その動作の各となるカーネルも Linux だけではなく他のカーネルに取り替えても
動作することを目指しています。この移植版としては

\begin{itemize}
 \item Hurd	（永遠の開発版？）
 \item kfreeBSD (i386, amd64)\footnote{NetBSD, OpenBSD は途中で作業する人の気力が尽きているようです。}
\end{itemize}

があります。\footnote{残念ながら Plan9 はありませんが、その上で動くツール類は移植されています。}

単に動作する機器／カーネルが多いだけではなく、その上のユーザランドのソフトも豊富で、
パッケージ化されており導入が容易になっています。現在リリースされている Debian 5.0 
コードネーム「Lenny」ではその数は25,000パッケージを越え、その数はさらに増えつづけています。
Linux で使えるソフトウェアを探す場合、大抵は既に Debian のパッケージとして提供されているので
気軽に試すことができるでしょう。

それから Debian で利用可能な言語は多種に渡ります。それは自然言語（英語、日本語など）
でもあり、計算機言語という意味でもあります\footnote{計算機言語の話は後で別の方が
滔々としてくれるでしょう :-)}。巷ではマイナーと呼ばれるような言語であっても
「Universal OS」を目指す Debian は積極的に取り込んでいます。例えば、ブータン公用語
「ゾンカ語」をサポートする DzongkhaLinux は Debian をベースに開発され、その成果は 
Debian に取り込まれています\footnote{これは商用OSでは「採算にあわない」ので
サポートが遅れがちになる少数言語／民族にとっての希望の現れと言えるでしょう}。


\subsubsection{フリー}
Debian の考える「フリー」は単に無料に止まらず、Debian フリーソフトウェアガイドライン
 (DFSG) という形でまとまっており、これが元になって「オープンソース」が生まれました。
この点が担保される、この考えを皆が共有することでさらに豊かなソフトウェア／コンテンツ／社会が
生まれています。このフリーというのは考えてみると中々奥深いものがありますので、ぜひ DFSG 
には一度目を通した上で Debian の考えるフリーという意味について Debian Developer の方などと
話をしてみてください。

\subsubsection{ボランティア}
最後のキーワードです。Debian はその開発や財政基盤を会社や財団に持たない極めて稀有な
開発集団です。大抵の有名ディストリビューションが企業をバックに開発をしていたり財団を
持ってそのいたりする\footnote{Fedora ← Red Hat, openSUSE ← Novell, Ubuntu ← Canonical, 
OpenOffice.org ← Oracle (Sun), Firefox ← Mozilla Foundation/Corporation など}のですが、
Debian 自体は財団や企業を持ちません\footnote{寄付などのために Software Public Interest 
という別法人がいますが、これは Debian だけではなく PostreSQL なども支援しています}。
ボランティアが世界中でインターネットを介して開発するという状態が10年以上も続けられており、
その規模は1000人を優に越えています。

\subsection{誰が Debian を使っているの?}
では、実際に誰が Debian を使っているのでしょうか? 「仕事で使うなら Red Hat 
Enterprise Linux かそのクローンの CentOS が普通だよね〜」などと言い切っている人は
いませんか? 実は、世の中に Debian で実際のビジネスを回している企業は山のようにあります。
その中にはあなたが知っている企業もあるはずです。また、開発に愛用しているという方も
少なくありません。あなたが使っているソフト／サービスは実は Debian が動いている／ベースに
なっている…かも知れませんよ。

\subsection{最後に}
簡単ではありますが、Debian の紹介をさせて頂きました。
これも何かの縁だし Debian を使ってみてもいいかな、と多少でも思っていただければ幸いです。


\subsection{Debian フリーソフトウェアガイドライン}
Debian フリーソフトウェアガイドライン全文(\url{http://www.debian.org/social_contract#guidelines})を掲載します。

\begin{figure}[h]
 {\small
1.「自由な再配布」…Debian システムを構成するソフトウェアのライセンスは、そのソフトウェアを、複数の異なる提供元から配布されているプログラムを集めたソフトウェア ディストリビューションの一部として、誰かが販売したり無料配布したりすることを 制限してはいけません。また、ライセンスはそのような販売に対して 使用料やその他の手数料を要求してはいけません。

2.「ソースコード」…プログラムにはソースコードが含まれていなければならず、 かつ実行形式での配布に加えてソースコードでの配布をも 許可していなければなりません。

3.「派生ソフトウェア」…ライセンスは、ソフトウェアの修正や派生ソフトウェアの作成、並びにそれら をオリジナルソフトウェアのライセンスと同じ条件の下で配布することを認め ていなけばいけません。

4.「原作者によるソースコードの整合性維持」…ライセンスは、プログラムを構築時に変更する目的でパッチファイル をソースコードとともに配布することを容認している場合に限り、 ソースコードを修正済の形式で配布することを制限することができます。 この場合、そのライセンスは修正済のソースコードから構築されたソフトウェアの 配布を明示的に許可していなければなりません。 またライセンスは派生ソフトウェアにオリジナルソフトウェアと異なる名前 を付けること、あるいは異なるバージョン番号を付けることを要求できます (これは妥協案です。Debian グループは全ての作者に、ファイル、 ソース、バイナリについての変更を制限しないよう奨めています)。

5.「すべての個人、団体の平等」…ライセンスは、すべての個人や団体を差別してはなりません。

6.「目標分野の平等」…ライセンスは、人々が特定の目標分野でプログラムを利用することを 制限してはいけません。たとえば、商用利用や、遺伝学の研究での プログラムの使用を制限していてはいけません。

7.「ライセンスの配布」…プログラムに付随する権利は、プログラムが再配布された すべての人々に対して、追加ライセンスの履行を必要とすることなく、 適用されなければなりません。

8.「ライセンスは Debian に限定されない」…プログラムに付随する権利は、プログラムが Debian システムの 一部であるかどうかに左右されてはいけません。 プログラムが Debian から取り出され Debian とは別に使用 または配布されるとしても、その他の点でそのプログラムの ライセンス条項を満たしているならば、プログラムが再配布された すべての当事者は Debian システムにおいて付与されたのと 同じ権利を与えられなければなりません。

9.「ライセンスは他のソフトウェアを侵害しない」…ライセンスは、そのソフトウェアとともに配布される他のソフトウェア に制約を加えてはなりません。たとえば、同じ媒体で配布される 他のソフトウェアがすべてフリーソフトウェアでなければならないと 要求してはいけません。

10.「フリーなライセンスの例」…GPL、BSD、および Artistic ライセンスは私たちがフリーと判断しているライセンスの例です。
}
\caption{The Debian Free Software Guidelines (DFSG)}
\label{fig:dfsg}
\end{figure}

% =======================================================================
\dancersection{DebianのOCaml環境で開発する関数型言語インタプリタ}{日比野啓}
\index{functional programming}
\index{OCaml}
\index{Haskell}
% =======================================================================

\subsection{OCaml はどんな言語}
\subsubsection{基本的な機能}

\subsection{関数型言語のインタプリタの簡単な作りかた}

関数型言語とは何でしょうか。
ここでは関数を値としてあつかえる言語ということにして、
そのような言語のインタプリタを作る話をします。

\subsubsection{環境渡しマシン}



 参考資料: \verb|http://www.sato.kuis.kyoto-u.ac.jp/~igarashi/class/isle4-05w/text/eopl003.html|

\subsection{OCamlでのlexingとparsing - ocamllexとocamlyacc}



\subsubsection{ocamllex}

ocamllexはOCamlに付属している字句解析関数生成器(lexer generator)で、
OCamlから呼び出せるlexerを生成してくれます。
以下のようにC言語でもおなじみの lex, flex と似たような使用感になっています。

\begin{commandline}

{
  (* header *)
  (* Lexingのルール部分で参照したい内容をOCamlで書く *)
}

(* 文字列パターンの定義 *)

(* 字句解析(lexing)のルール記述 *)

{
  (* trailer *)
  (* ルール部分で生成された関数を参照する内容をOCamlで書く *)
}

\end{commandline}

\subsubsection{ocamlyacc}

同様に、ocamlyaccはOCamlに付属している構文解析関数生成器(parser generator)で、
OCamlから呼び出せるparserを生成してくれます。
こちらもやはり、以下のように yacc, bison と似たような使用感になっています。

\begin{commandline}

%{
  (* header *)
  (* 構文木生成処理で参照したい内容をOCamlで書く *)
%}
  /* declarations */
  /* 終端記号の型や構文木のrootの宣言 */
%%
  /* rules */
  /* 文脈自由文法と構文木生成処理を記述 */
%%
  (* trailer *)
  (* 生成されたparserの関数を参照する内容をOCamlで書く *)

\end{commandline}

\subsubsection{ocamllexとocamlyaccの使用例}

ocamllexとocamlyaccを併用する場合には、
ocamlyaccで生成させたparserの終端記号の定義を
lexerから参照させるようにするのがもっとも単純な使い方です。

以下がS式parserを生成させる例です。
sParser.mlyをocamlyaccで処理するとsParser.mlが生成され、
sLexer.mllをocamllexで処理するとsLexer.mlが生成されます。

\par
\paragraph{sParser.mly}
型ごとに終端記号を\%tokenで宣言し、
\%startと\%typeで構文木のrootとその型を指定します。
rootの名前が構文解析関数の名前になります。

yaccと同じ要領で文脈自由文法を記述していきます。
exprは真偽値、数値、文字列であるか、
あるいは、exprドット対またはexprを並べたもの を括弧で括ったものという定義になっています。

\begin{commandline}

%{
  (* sParser.mly *)

  module C = SCons

%}

/* File sparser.mly */
%token LPAREN RPAREN DOT_SYMBOL EOL BOOL_TRUE BOOL_FALSE
%token <SCons.s_int> INT
%token <float> FLOAT
%token <string> SYMBOL
%token <string> STRING
%start expr
%type <SCons.s_expr> expr
%%

expr_list:
  { C.Null }
| expr DOT_SYMBOL expr { C.Cons($1, $3) }
| expr expr_list { C.Cons($1, $2) }

expr:
| BOOL_TRUE               { C.Bool(true) }
| BOOL_FALSE              { C.Bool(false) }
| INT                     { C.Int($1) }
| FLOAT                   { C.Float($1) }
| SYMBOL                  { C.Symbol($1) }
| STRING                  { C.String($1) }
| LPAREN expr_list RPAREN { $2 }

\end{commandline}

% $ dummy comment

\par
\paragraph{sLexer.mll}
文字列パターンの定義では、正規表現の要領で文字集合や繰り返しの表現を利用して
定義を作り、letで名前を付けていきます。文字を '' でくくる以外は正規表現と同様です。
定義した文字列パターンをさらに別の文字列パターンに再利用することができます。

ルール記述の部分では、tokenの文字列パターンとtoken生成式をlexの要領で記述していきます。
キーワードruleの後の文字列がlexerの関数名になります。なのでここではその関数の名前はtokenです。

字句解析(Lexing)の過程における入力ファイル内の位置は、
lexbufのlex\_start\_pに記号(token)の開始位置が、
lex\_curr\_pにtokenの終了の次の位置が保持されています。
ocamllexデフォルトの動作ではpos\_cnum フィールドが更新されるのみなので、
ファイル先頭からのバイト数しかわかりません。
陽に行数の認識やタブによるカラム数の補正を行なう場合には、
lex\_start\_pとtokenをもとにlex\_curr\_pを修正してやる必要があります。
\footnote{次のlex\_start\_pは現在のlex\_curr\_pから引き継がれるので、
lex\_curr\_pを修正すれば十分です。}



\begin{commandline}
{
  (* sLexer.mll*)

  module LX = Lexing
  module P = SParser
  ... (* 中略 *)
  let fix_position lexbuf =
    let newline pos = {
      pos with
	LX.pos_lnum = pos.LX.pos_lnum + 1;
	LX.pos_cnum = pos.LX.pos_cnum + 1;
	LX.pos_bol = pos.LX.pos_cnum + 1;
    } in

    let tab pos = {
      pos with
	LX.pos_cnum = pos.LX.pos_cnum + 8 - (pos.LX.pos_cnum - pos.LX.pos_bol) mod 8
    } in

    let other pos = {
      pos with
	LX.pos_cnum = pos.LX.pos_cnum + 1
    } in

    let rec fix_pos_rec pos str =
      let len = (String.length str) in
	match (if len > 0 then (Some (str.[0]), String.sub str 1 (len - 1))
	       else (None, "")) with
	    (None, _) -> pos
	  | (Some '\n', rest) -> fix_pos_rec (newline pos) rest
	  | (Some '\t', rest) -> fix_pos_rec (tab pos) rest
	  | (Some _, rest) -> fix_pos_rec (other pos) rest
    in
    let _ = lexbuf.LX.lex_curr_p <- fix_pos_rec (LX.lexeme_start_p lexbuf) (LX.lexeme lexbuf) in
      ()
}

/* 文字列パターンの定義 */
let str_esc = '\\'
let double_quote = '"'
let str_escaped_char = str_esc _
let str_char = [^ '\\' '"']
let str = double_quote (str_char | str_escaped_char)* double_quote

let left_paren = '('
let right_paren = ')'
let space = [' ' '\t' '\n' '\r']+
let dot_symbol = '.'
let bool_true  = '#' 't'
let bool_false = '#' 'f'

let int = '-'? ['0' - '9']+
let float = '-'? ['0' - '9']+ '.' ['0' - '9']* | '-'? ['0' - '9']* '.' ['0' - '9']+
let symbol = [^ '"' '(' ')' ' ' '\t' '\n' '\r']+

/* lexingのルール記述 */
rule token = parse
  | left_paren      { P.LPAREN }
  | right_paren     { P.RPAREN }
  | space      { fix_position lexbuf; token lexbuf }
  | dot_symbol      { P.DOT_SYMBOL }
  | bool_true       { P.BOOL_TRUE }
  | bool_false      { P.BOOL_FALSE }
  | int      { expr_integer (LX.lexeme lexbuf) }
  | float    { P.FLOAT(Pervasives.float_of_string(LX.lexeme lexbuf)) }
  | symbol   { P.SYMBOL(LX.lexeme lexbuf) }
  | str      { fix_position lexbuf; P.STRING(expr_string(LX.lexeme lexbuf)) }
  | eof      { raise Eof }

\end{commandline}

%\pagebreak

\subsection{HaskellのLexing}

Haskellには
ブロックの開始や終了のtokenや式の区切りのtokenを省略することができる
layout ruleという機能があります。
そのため省略されたtokenをlexingの過程で補ってやる必要があります。

まず、通常と同様にlexingを行なってtoken列を生成し、
そのtoken列に規則に従ってtokenを補うというように、2段階の工程を行ないます。

\subsubsection{layoutなしのLexing}

\paragraph{lexer0.mll header部分}

まずは.mllのheader部分です。

後からlayout ruleにおいて必要となるカラム数を数えあげるための処理を行なう関数(fix\_position)や、
Haskellの文字および文字列リテラルはリテラル内のルールが複雑度の高い仕様なので、
別のlexer(後述)を呼び出しつつ実際の文字列表現を構成する関数(decode\_char, decode\_string)を準備しています。

\begin{commandline}
{
  (* lexer0.mll header部分 *)
  module LX = Lexing
  module P = Parser
  ... (* 中略 *)
  let fix_position lexbuf =
    let newline pos =
      { pos with
          LX.pos_lnum = pos.LX.pos_lnum + 1;
          LX.pos_cnum = pos.LX.pos_cnum + 1;
          LX.pos_bol = pos.LX.pos_cnum + 1;
      } in

    let tab pos =
      { pos with
          LX.pos_cnum = pos.LX.pos_cnum + 8 - (pos.LX.pos_cnum - pos.LX.pos_bol) mod 8
      } in

    let other pos =
      { pos with
          LX.pos_cnum = pos.LX.pos_cnum + 1
      } in

    let rec fix_pos_rec pos str =
      let len = (String.length str) in
        match (if len > 0 then (Some (str.[0]), String.sub str 1 (len - 1))
               else (None, "")) with
            (None, _) -> pos
          | (Some '\n', rest) -> fix_pos_rec (newline pos) rest
          | (Some '\t', rest) -> fix_pos_rec (tab pos) rest
          | (Some _, rest) -> fix_pos_rec (other pos) rest
    in
    let _ = lexbuf.LX.lex_curr_p <- fix_pos_rec (LX.lexeme_start_p lexbuf) (LX.lexeme lexbuf) in
      ()
  ... (* 中略 *)
  let decode_cexpr cexpr =
    let fchar = String.get cexpr 0 in
    let escexp = String.sub cexpr 1 ((String.length cexpr) - 1) in
    let fmatch exp str = Str.string_match (Str.regexp exp) str 0 in
      if fchar = '\\' then
        match escexp with
            "NUL"   -> Some '\x00'
          | "SOH" | "^A"   -> Some '\x01'
          | "STX" | "^B"   -> Some '\x02'
        ... (* 中略 *)
          | "RS"  | "^^"   -> Some '\x1e'
          | "US"  | "^_"   -> Some '\x1f'
          | "SP"           -> Some ' '

          | "\\"           -> Some '\\'
          | "\""           -> Some '"'
          | "'"            -> Some '\''

          | "DEL"          -> Some '\x7f'

          | _ when fmatch "^[0-9]+$" escexp
              -> Some (Char.chr (int_of_string escexp))
          | _ when fmatch "^[xX][0-9a-zA-Z]+$" escexp 
              -> Some (Char.chr (int_of_string ("0" ^ escexp)))
          | _ when fmatch "^[oO][0-7]+$" escexp
              -> Some (Char.chr (int_of_string ("0" ^ escexp)))

          | _ -> None

      else Some fchar

  let decode_char lexbuf =
    let cstr = LX.lexeme lexbuf in
    let len = String.length cstr in
      match decode_cexpr (String.sub cstr 1 (len - 2)) with
          Some c -> c
        | None   -> failwith (F.sprintf "Unkown char expression %s" cstr)

  let decode_string lexbuf =
    let sexpr = LX.lexeme lexbuf in
    let len = String.length sexpr in
    let strlbuf = Lexing.from_string (String.sub sexpr 1 (len - 2)) in
    let rec decode result =
      match HsStr.char strlbuf with
          HsStr.Eos -> result
        | HsStr.Char cstr ->
            if cstr = "\\&" then decode (result ^ "&")
            else decode (result ^ 
                           match (decode_cexpr cstr) with
                               None -> failwith (F.sprintf "Unkown char expression '%s' in literal string" cstr)
                             | Some c -> (String.make 1 c))
        | HsStr.Gap g -> decode result
    in decode ""
}
\end{commandline}

% $ dummy comment

\paragraph{lexer0.mll 文字列パターン定義部分}

次に文字列パターンの定義です。

行数はちょっと多いですが、特に難しいところはありません。
問題のリテラル文字列ですが、リテラル文字列部分の文字列パターン自体は問題なく表現できています。
しかし、リテラルで表現される文字列自体を復元するのが複雑なので前記および後述のような準備が必要になります。

\begin{commandline}
/* lexer0.mll 文字列パターン定義部分 */
let special = ['(' ')' ',' ';' '[' ']' '`' '{' '}']

let space = ' '
let newline = ("\r\n"|['\n' '\r'])
let tab = '\t'

let dashes = '-' '-' '-'*

let ascSmall = ['a'-'z']
let small = ascSmall | '_'
let ascLarge = ['A'-'Z']
let large = ascLarge

let plus = '+'
let minus = '-'
let exclamation = '!'
let ascSymbol_nbs = [ '!' '#' '$' '%' '&' '*' '+' '.' '/' '<' '=' '>' '?' '@' '^' '|' '-' '~' ]
let ascSymbol = ascSymbol_nbs | '\\'
let symbol = ascSymbol

let ascDigit = ['0'-'9']
let digit = ascDigit

let octit = ['0'-'7']
let hexit = ascDigit | ['a'-'z' 'A'-'Z']

let decimal = (digit)+
let octal = (octit)+
let hexadecimal = (hexit)+

let exponent = ['e' 'E'] ['+' '-']? decimal
let float = decimal '.' decimal exponent? | decimal exponent

let graphic = small | large | symbol | digit | special | [':' '"' '\'']
let any = graphic | space | tab

let comment = dashes ((space | tab | small | large | symbol | digit | special | [':' '"' '\'']) (any)*)? newline

let whitechar = newline | space | tab
let whitestuff = whitechar | comment 
let whitespace = (whitestuff)+

(*
let lwhitechar = space | tab
let lwhitestuff = lwhitechar | comment 
let lwhitespace = (lwhitestuff)+
*)

let char_gr = small | large | ascSymbol_nbs | digit | special | [':' '"']
let str_gr  = small | large | ascSymbol_nbs | digit | special | [':' '\'']

let charesc = ['a' 'b' 'f' 'n' 'r' 't' 'v' '\\' '"' '\'']
let str_charesc = charesc | '&'
let cntrl = ascLarge | ['@' '[' '\\' ']' '^' '_']
let gap = '\\' (whitechar)+ '\\'
(* let gap = '\\' (lwhitechar | newline)+ '\\' *)

let ascii = ('^' cntrl) | "NUL" | "SOH" | "STX" | "ETX" | "EOT" | "ENQ" | "ACK"
  | "BEL" | "BS" | "HT" | "LF" | "VT" | "FF" | "CR" | "SO" | "SI" | "DLE"
  | "DC1" | "DC2" | "DC3" | "DC4" | "NAK" | "SYN" | "ETB" | "CAN"
  | "EM" | "SUB" | "ESC" | "FS" | "GS" | "RS" | "US" | "SP" | "DEL"

let escape = '\\' ( charesc | ascii | decimal | 'o' octal | 'x' hexadecimal )
let str_escape = '\\' ( str_charesc | ascii | decimal | 'o' octal | 'x' hexadecimal )

let char = '\'' (char_gr | space | escape) '\''
let string = '"' (str_gr | space | str_escape | gap)* '"'

let varid = small (small | large | digit | '\'')*
let conid = large (small | large | digit | '\'')*

let varsym = symbol (symbol | ':')*
let consym = ':' (symbol | ':')*

let modid = conid
\end{commandline}

% $ dummy comment

\paragraph{lexer0.mll ルール記述部分}

最後にルール記述です。

スペース、タブ、改行などを含んでいるwhitespaceやstringのところで
fix\_positionを呼んで位置情報を補正しています。
またcharやstringのリテラルから文字や文字列を構成するために
decode\_char, decode\_string を呼び出しています。

\begin{commandline}
(* lexer0.mll ルール記述部分 *)
rule token = parse
  | '('  { P.SP_LEFT_PAREN(loc lexbuf) }
  | ')'  { P.SP_RIGHT_PAREN(loc lexbuf) }
  | ','  { P.SP_COMMA(loc lexbuf) }
  | ';'  { P.SP_SEMI(loc lexbuf) }
  | '['  { P.SP_LEFT_BRACKET(loc lexbuf) }
  | ']'  { P.SP_RIGHT_BRACKET(loc lexbuf) }
  | '`'  { P.SP_B_QUOTE(loc lexbuf) }
  | '{'  { P.SP_LEFT_BRACE(loc lexbuf) }
  | '}'  { P.SP_RIGHT_BRACE(loc lexbuf) }
      (** special tokens *)

  | "case"     { P.K_CASE(loc lexbuf) }
  | "class"    { P.K_CLASS(loc lexbuf) }
  | "data"     { P.K_DATA(loc lexbuf) }
  | "default"  { P.K_DEFAULT(loc lexbuf) }
  | "deriving" { P.K_DERIVING(loc lexbuf) }
  | "do"       { P.K_DO(loc lexbuf) }
  | "else"     { P.K_ELSE(loc lexbuf) }
  | "if"       { P.K_IF(loc lexbuf) }
  | "import"   { P.K_IMPORT(loc lexbuf) }
  | "in"       { P.K_IN(loc lexbuf) }
  | "infix"    { P.K_INFIX(loc lexbuf) }
  | "infixl"   { P.K_INFIXL(loc lexbuf) }
  | "infixr"   { P.K_INFIXR(loc lexbuf) }
  | "instance" { P.K_INSTANCE(loc lexbuf) }
  | "let"      { P.K_LET(loc lexbuf) }
  | "module"   { P.K_MODULE(loc lexbuf) }
  | "newtype"  { P.K_NEWTYPE(loc lexbuf) }
  | "of"       { P.K_OF(loc lexbuf) }
  | "then"     { P.K_THEN(loc lexbuf) }
  | "type"     { P.K_TYPE(loc lexbuf) }
  | "where"    { P.K_WHERE(loc lexbuf) }
  | "_"        { P.K_WILDCARD(loc lexbuf) }
      (** reservedid *)

  | ".."       { P.KS_DOTDOT(loc lexbuf) }
  | ":"        { P.KS_COLON(loc lexbuf) }
  | "::"       { P.KS_2_COLON(loc lexbuf) }
  | "="        { P.KS_EQ(loc lexbuf) }
  | "\\"       { P.KS_B_SLASH(loc lexbuf) }
  | "|"        { P.KS_BAR(loc lexbuf) }
  | "<-"       { P.KS_L_ARROW(loc lexbuf) }
  | "->"       { P.KS_R_ARROW(loc lexbuf) }
  | "@"        { P.KS_AT(loc lexbuf) }
  | "~"        { P.KS_TILDE(loc lexbuf) }
  | "=>"       { P.KS_R_W_ARROW(loc lexbuf) }
      (** reservedop *)

  | "as"              { P.K_AS(loc lexbuf) }  (** maybe varid *)
  | "qualified"       { P.K_QUALIFIED(loc lexbuf) }  (** maybe varid *)
  | "hiding"          { P.K_HIDING(loc lexbuf) }  (** maybe varid *)
  | varid      { P.T_VARID(LX.lexeme lexbuf, loc lexbuf) }
  | conid      { P.T_CONID(LX.lexeme lexbuf, loc lexbuf) }
      (** identifiers or may be qualified ones *)

  | whitespace  { fix_position lexbuf; P.WS_WHITE(loc lexbuf) }  (** comment begining with dashes is not varsym *)
      (** white spaces *)

  | plus       { P.KS_PLUS(loc lexbuf) }  (** maybe varsym *)
  | minus      { P.KS_MINUS(loc lexbuf) } (** maybe varsym *)
  | exclamation  { P.KS_EXCLAM(loc lexbuf) } (** maybe varsym *)
  | varsym     { P.T_VARSYM(LX.lexeme lexbuf, loc lexbuf) }
  | consym     { P.T_CONSYM(LX.lexeme lexbuf, loc lexbuf) }
      (** symbols or may be qualified ones *)

  | modid '.' varid   { P.T_MOD_VARID(decode_with_mod lexbuf, loc lexbuf) }
  | modid '.' conid   { P.T_MOD_CONID(decode_with_mod lexbuf, loc lexbuf) }
  | modid '.' varsym  { P.T_MOD_VARSYM(decode_with_mod lexbuf, loc lexbuf) }
  | modid '.' consym  { P.T_MOD_CONSYM(decode_with_mod lexbuf, loc lexbuf) }
      (** qualified xx *)

  | char      { P.L_CHAR(decode_char lexbuf, loc lexbuf) }
  | string    { fix_position lexbuf; P.L_STRING(decode_string lexbuf, loc lexbuf) }

  | decimal | ('0' ['o' 'O'] octal) | ('0' ['x' 'X'] hexadecimal)
        { P.L_INTEGER(Int64.of_string(LX.lexeme lexbuf), loc lexbuf) }

  | float      { P.L_FLOAT(float_of_string(LX.lexeme lexbuf), loc lexbuf) }

  | eof        { P.EOF(loc lexbuf) }
  ... /* 以下略 */
\end{commandline}


\paragraph{hsStr.mll}

文字列のlexerです。

ここでのtokenは文字列リテラル内の1文字の表現あるいはギャップ(gap)です。
Haskellでは1つの文字列リテラルを中断して、
間に空白や改行やコメントを記述した後に、再開することができます。
この空白や改行やコメントの部分がgapです。

ここで定義されたchar関数を利用してdecode\_string関数は文字列を構成していくようになっています。

\begin{commandline}
{
  (* hsStr.mll *)
  module LX = Lexing

  type ct =
      Char of string
    | Gap of string
    | Eos
}

let special = ['(' ')' ',' ';' '[' ']' '`' '{' '}']

let space = ' '
let newline = ("\r\n"|['\n' '\r'])
let tab = '\t'

let ascSmall = ['a'-'z']
let small = ascSmall
let ascLarge = ['A'-'Z']
let large = ascLarge

let ascSymbol_nbs = [ '!' '#' '$' '%' '&' '*' '+' '.' '/' '<' '=' '>' '?' '@' '^' '|' '-' '~' ]

let ascDigit = ['0'-'9']
let digit = ascDigit

let octit = ['0'-'7']
let hexit = ascDigit | ['a'-'z' 'A'-'Z']

let decimal = (digit)+
let octal = (octit)+
let hexadecimal = (hexit)+

let lwhitechar = space | tab

let str_gr  = small | large | ascSymbol_nbs | digit | special | [':' '\'']

let charesc = ['a' 'b' 'f' 'n' 'r' 't' 'v' '\\' '"' '\'']
let str_charesc = charesc | '&'
let cntrl = ascLarge | ['@' '[' '\\' ']' '^' '_']
let gap = '\\' (lwhitechar | newline)+ '\\'

let ascii = ('^' cntrl) | "NUL" | "SOH" | "STX" | "ETX" | "EOT" | "ENQ" | "ACK"
  | "BEL" | "BS" | "HT" | "LF" | "VT" | "FF" | "CR" | "SO" | "SI" | "DLE"
  | "DC1" | "DC2" | "DC3" | "DC4" | "NAK" | "SYN" | "ETB" | "CAN"
  | "EM" | "SUB" | "ESC" | "FS" | "GS" | "RS" | "US" | "SP" | "DEL"

let str_escape = '\\' ( str_charesc | ascii | decimal | 'o' octal | 'x' hexadecimal )

rule char = parse
  | str_gr | space | str_escape  { Char(LX.lexeme lexbuf) }
  | gap                          { Gap(LX.lexeme lexbuf) }
  | eof                          { Eos }
\end{commandline}

% $ dummy comment

参考資料: \verb|http://www.sampou.org/haskell/report-revised-j/lexemes.html|

\subsubsection{Haskellのlayout rule}

この節の始めにも書いたようにlayout ruleは、
token列にさらにtokenを補ってやる処理です。
まずは補うルールを確認してみましょう。
以下に、Haskell 98 Language Reportの改訂版の和訳
\footnote{http://www.sampou.org/haskell/report-revised-j/syntax-iso.html\#layout}から引用してみます。

%%\paragraph{--- 引用ここから ---} \ 

\dotfill 引用ここから\dotfill

%% \par
%% \begin{tabular}{c|c|c}
%% \cline{1} & 引用ここから & \cline{3} \\
%% \end{tabular}

 レイアウトの影響は、この節では、レイアウトを用いているプログラムに、どのようにして、ブレースとセミコロンを追加するかを記述することによって指定する。この仕様は、変換を行う関数 L の形をとる。L  への入力は

\begin{itemize}

    \item この Haskell レポートの字句構文で指定されたような字句の並びで、以下のような追加トークンがついているもの。

    \begin{itemize}
          \item キーワード let、where、do あるいは of のあとに字句 \{ が続かない場合、トークン $\{n\}$ をキーワードの後に挿入する。ここで n は、もし次の字句があればそれのインデント、または、ファイルの終端に到達していれば 0 である。
          \item モジュールの最初の字句が \{ あるいは module では ないとき、その字句の前に $\{n\}$ を置く。ここで、n はその字句のインデントである。
          \item 同一行で、字句の開始の前には白空白しかないとき、この字句の前に $<n>$ を置く。ここで n はこの字句のインデントで、 前の二つの規則の結果、その前には $\{n\}$ が置かれていない。 (注意: 文字列リテラルは複数行にまたがることがある -- 2.6 節。したがって、
\begin{commandline}
              f = ("Hello \
                      \Bill", "Jake")
\end{commandline}
            では、\verb|\Bill| の前に $<n>$ は挿入されることはない。なぜなら、完全な字句の開始場所ではないからだ。また、, の前にも $<n>$ は置かれることはない。なぜなら、その前に 白空白以外のものがあるからだ。)
    \end{itemize}

    \item「レイアウト文脈」のスタックのそれぞれの要素は以下のどれかである。

    \begin{itemize}
          \item ゼロ、これは文脈を明示的に囲うこと(たとえばプログラマが開ブレース を用意した場合)を示す。もし最も内側の文脈が 0 なら、囲まれた文脈が 終了するか、新しい文脈がプッシュされるまで、レイアウトトークンは挿 入されない。
          \item 正の整数、これは囲まれたレイアウト文脈のインデントカラム数
    \end{itemize}

\end{itemize}

字句の「インデント」は字句の最初の文字のカラム数である。
ひとつの行のインデントとは最も左にある字句のインデントを表す。
このカラム数を決定するために以下のような規約をもつ固定幅のフォントを仮定する。

\begin{itemize}
    \item 改行、リターン、ラインフィードおよびフォームフィード文字はすべて新しい行を開始する
    \item 最初のコラムは 0 ではなく 1 である
    \item タブストップは8文字文ずつの位置にある
    \item タブ文字は現在位置から次のタブストップ位置までそろえるのに必要なだけの空白を挿入する。
\end{itemize}

レイアウトルールにあわせるために、ソースプログラム中の Unicode 文字は ASCII 文字と同じ幅の固定幅であると看倣す。しかしながら、見た目との混 乱を避けるためプログラマは暗黙のレイアウトの意味が非空白文字の幅に依 存するようなプログラムを書かないようにすべきである。

\paragraph{適用} \ 

L tokens [ ] は、tokens のレイアウトに関知しない変換をもたらす。
ここで、tokens はモジュールの字句解析および上述のようにカラム数表示子を追加した結果である。
L の定義は以下のとおり、ここでは 「:」をストリーム構築操作子として使い、「[ ]」は空のストリームである。

\begin{commandline}
L (<n>:ts) (m:ms)   = ; : (L ts (m:ms))  if m = n
                    = } : (L (<n>:ts) ms) if n < m
L (<n>:ts) ms       = L ts ms
L ({n}:ts) (m:ms)   = { : (L ts (n:m:ms)) if n > m   (Note 1)
L ({n}:ts) []       = { : (L ts [n]) if n > 0        (Note 1)
L ({n}:ts) ms       = { : } : (L (<n>:ts) ms)        (Note 2)
L (}:ts) (0:ms)     = } : (L ts ms)                  (Note 3)
L (}:ts) ms         = parse-error                    (Note 3)
L ({:ts) ms         = { : (L ts (0:ms))              (Note 4)
L (t:ts) (m:ms)     = } : (L (t:ts) ms) if m /= 0 and parse-error(t)  (Note 5)
L (t:ts) ms         = t : (L ts ms)
L [] []             = []
L [] (m:ms)         = } : L [] ms if m /=0           (Note 6)
\end{commandline}


%% \paragraph{Note 1.}

%% 入れ子になった文脈は、囲まれた文脈 ($n>m$) よりも深くインデ ントされていなければならない。
%% さもなければ、L は失敗し、また、コンパイラはレイアウトエラーを表示しなければならない。たとえば、

%% \begin{commandline}
%%   f x = let
%%            h y = let
%%     p z = z
%%                  in p
%%         in h
%% \end{commandline}

%% ここで、p の定義は囲まれた文脈のインデントよりも浅いインデントである。
%% この場合、h の定義によって設定される。

%% \paragraph{Note 2.}

%% where の後の最初のトークンが、たとえば、囲まれた文脈よりもインデントされているのでなければ、
%% そのブロックは空でなければならない。 
%% だから、空のブレースが挿入される。
%% トークン $\{n\}$ は $<n>$ に置き換 えられ、空のブレースが明示的になっていた場合の状況を模倣する。

%% \paragraph{Note 3.}

%% 現在のレイアウト文脈について 0 に対して照合することで、
%% 明示的な閉ブレースが明示的な開ブレースにのみ対応することを確かめる。
%% もし、明示的 な閉ブレースが暗黙の開ブレースに対応している場合には構文解析エラーとなる。

%% \paragraph{Note 4.}

%% これは、すべてのブレースの対は明示的なレイアウト文脈として扱われることを意味し、
%% ラベル付のデータ構築および更新 (3.15 節)を含む。ここにこの形式化と Haskell 1.4 での違いがある。

%% \paragraph{Note 5.}

%% 副次的な条件 parse-error(t) は次のように解釈される。
%% もし、次の トークンが t であるような L によって生成されたトークンが Haskell の文法の不正な接頭辞を表わしている場合、
%% および、 「\}」トークンが続く L によって生成さたトークンの Haskell 文法の正しい接頭辞である場合、parse-error(t) は真とな る。

%% $m /= 0$ のチェックは、暗黙に追加された閉ブレースが、暗黙の開ブレースに 対応することをたしかめる。

%% \paragraph{Note 6.}

%% 入力の終端において、保留された閉ブレースがすべて挿入される。
%% この時点 でレイアウト文脈のなかにある(すなわち、$m = 0$ である)とエラーとなる。


\dotfill 引用ここまで 以下略 \dotfill

わかりにくいですが、ここでも内部的には2段階になっています。

まず元のtoken列のひとつめの操作を適用します。以下のような規則だと考えるとわかりやすいかもしれません。

\begin{itemize}
 \item let, where, do, of の後に \{ が無い場合には代わりにブロックの開始をあらわす token $\{n\}$ を挿入。
 \item ファイルの先頭もモジュール宣言が省略されていて \{ が無い場合には token $\{n\}$ でブロック開始。
 \item インデントのレベルで後からブロックを認識するために token $<n>$ を挿入しておく。
\end{itemize}

つぎにふたつめの操作である関数 L を適用します。

L はもとのtoken列とインデントレベルのスタックを引数にとり、
もとのtoken列にtokenを挿入したものを返す関数です。
やはり以下のような規則だと考えるとわかりやすいかもしれません。

\begin{itemize}
 \item インデントレベル$<n>$ が同じレベルのブロック内であれば(スタック参照) ; を挿入して式を終了、ブロックを継続
 \item インデントレベル$<n>$の方が浅ければ \} を挿入してブロックを終了
 \item インデントレベル$<n>$があって上のどちらでもなければ式を継続

 \item あるブロック内で(スタック参照)よりインデントレベルの深いブロック開始$\{n\}$があったら \{ を挿入しブロックを開始。
ブロック開始をあらわすインデントレベルnをスタックに積む
 \item ブロック開始 $\{n\}$ が最も外側でも同様にブロック開始。 \{ を挿入し、nをスタックに積む
 \item ブロック開始 $\{n\}$ があって上のどちらでもなければ \{ および \} を挿入し空のブロックを作る。
実はブロック開始ではなかったということがここでわかるので代わりに $<n>$ を挿入する。

 \item \} があったらスタックから 0 を取り出す
 \item \} があって 0 を降ろせなかったら parse error

 \item \{ があったらスタックに 0 を積む

 \item 上のどれでもなく、またブロック内であり、ブロックを継続すると parse error になるときは \} を挿入してブロックを閉じる。
 \item 上のどれでもなく、またブロック内であるときは parse error にならない限りブロックを継続。
 \item トークンもスタックも空ならおわり
 \item トークンが空でスタックに 0 でない値が残っているなら \} を挿入してスタックから取り出す。( 0があったらエラー )
\end{itemize}

\paragraph{OCamlでの実装} \ 

OCamlで上layout ruleを実装した関数が以下のような感じです。
P.BLK\_OPEN が $\{n\}$ で P.BLK\_LEVEL が $<n>$ にあたるものです。

「parse error にならない限りブロックを継続」のルールはかなり実装がやっかいでした。
これはparserのところで後述します。

\begin{commandline}
let all_token_rev_list lexbuf =
  let unget_s = S.create () in
  let get_token () = L0.token lexbuf in
  let blk_level_pair tk =
    let loc = L0.get_location tk in (loc.T.start_p.T.col + 1, loc) in
  let eof_token_p = (function P.EOF(_) -> true | _ -> false) in

  let rec scan_start () =
    match get_token () with
        (P.SP_LEFT_BRACE _ | P.K_MODULE _) as start -> start
(*       | P.WS_NEWLINE _ -> scan_start () *)
      | P.WS_WHITE _ -> scan_start ()
      | other ->
          let _ = S.push other unget_s in
            P.BLK_OPEN (blk_level_pair other)
  in

  let scan_next prev = 
    let rec scan_next_rec () =
      let cur =
        if (S.is_empty unget_s) then (get_token ())
        else (S.pop unget_s) in

        match (prev, cur) with
            (_, (P.EOF(_) as eoft)) -> eoft
          | (_, P.WS_WHITE(_)) -> (scan_next_rec ())
(*        | (_, P.WS_NEWLINE(_)) -> (scan_next_rec ()) *)
          | ((P.K_LET(_) | P.K_WHERE(_) | P.K_DO(_) | P.K_OF(_)), (P.SP_LEFT_BRACE(_) as lbr)) -> lbr
          | ((P.K_LET(_) | P.K_WHERE(_) | P.K_DO(_) | P.K_OF(_)), tk) ->
              let (_, (level, loc)) = (S.push tk unget_s, blk_level_pair tk) in
                P.BLK_OPEN((if (eof_token_p tk) then 0 else level), loc)
          | (_, tk) ->
              let (_, loc) as p = blk_level_pair tk in
                if (loc.T.start_p.T.line
                    - (L0.get_location prev).T.end_p.T.line) > 0 then
                  let _ = S.push tk unget_s in P.BLK_LEVEL p
                else tk
    in (scan_next_rec ())
  in
    (* LST.create_stream (scan_start ()) scan_next eof_token_p *)
    (LST.fold_left
       (fun r a -> ((a, new_err_flag ()) :: r))
       []
       (LST.create_stream (scan_start ()) scan_next eof_token_p))
... (* 中略 *)
let rec layout istream levels =
  let push_new_token tok lform =
    LST.Cons ((tok, new_err_flag ()), lform)
  in

  let (tok, err) =
    match LST.peek istream with
        None -> raise Parsing.Parse_error
      | Some x -> x
  in
    match (tok, levels) with
        ((P.BLK_LEVEL (n, loc)), (m :: mstl as ms)) when m = n ->
          let addtk = P.SP_SEMI(loc) in
            push_new_token addtk (lazy (layout (LST.tl istream) ms))
      | ((P.BLK_LEVEL (n, loc)), m :: ms) when n < m  ->
          push_new_token (P.SP_RIGHT_BRACE(loc)) (lazy (layout istream ms))
      | ((P.BLK_LEVEL (n, _)), ms)                         -> layout (LST.tl istream) ms
      | ((P.BLK_OPEN (n, loc)), (m :: ms as levels)) when n > m  ->
          push_new_token (P.SP_LEFT_BRACE(loc)) (lazy (layout (LST.tl istream) (n :: levels))) (* Note 1 *)
      | ((P.BLK_OPEN (n, loc)), []) when n > 0             ->
          push_new_token (P.SP_LEFT_BRACE(loc)) (lazy (layout (LST.tl istream) [n])) (* Note 1 *)
      | ((P.BLK_OPEN (n, loc)), ms)                        ->
          push_new_token
            (P.SP_LEFT_BRACE(loc))
            (lazy (push_new_token
                     (P.SP_RIGHT_BRACE(loc))
                     (lazy (layout (push_new_token
                                      (P.BLK_LEVEL(n, loc))
                                      (lazy (LST.tl istream))) ms)))) (* Note 2 *)
      | ((P.SP_RIGHT_BRACE _ as rbr), 0 :: ms)        ->
          LST.Cons ((rbr, err), lazy (layout (LST.tl istream) ms)) (* Note 3 *)
      | ((P.SP_RIGHT_BRACE _), ms)                   -> raise Parsing.Parse_error (* Note 3 *)
      | ((P.SP_LEFT_BRACE _ as lbr), ms)             -> LST.Cons ((lbr, err), lazy (layout (LST.tl istream) (0 :: ms))) (* Note 4 *)

      | ((P.EOF loc as eoft), [])                    -> LST.Cons ((eoft, err), lazy (LST.Nil))
      | ((P.EOF loc), m :: ms) when m <> 0       -> push_new_token (P.SP_RIGHT_BRACE(loc)) (lazy (layout istream ms)) (* Note 6 *)

      | (t, (m :: mstl)) when m <> 0 && (!err)       ->
          err := false;
          push_new_token (P.SP_RIGHT_BRACE(L0.get_location t)) (lazy (layout istream mstl))  (* parse-error(t) Note 5 case *)
      | (t, ((m :: mstl) as ms))                   ->
          LST.Cons ((t, err),
                   lazy (layout (LST.tl istream) ms))
      | (t, ms)                                    ->
          LST.Cons ((t, err),
                   lazy (layout (LST.tl istream) ms))
\end{commandline}

参考資料: \verb|http://www.sampou.org/haskell/report-revised-j/syntax-iso.html#layout|
    

\subsection{HaskellのParsing}

\subsubsection{ocamlyaccによるParsing}

\begin{commandline}
\end{commandline}

\subsubsection{二項演算子の優先順位}

\subsubsection{あいまい文法の問題}

\subsection{HaskellのEvaluator}

\subsubsection{遅延評価}

\subsubsection{遅延パターンマッチ}

% =======================================================================
\dancersection{ブート方法が変わるよ}{まえだこうへい}
\index{upstart}
% =======================================================================

\subsection{Squeeze からブート方法が変わる}

\subsubsection{Upstart とは}

\subsubsection{init 系との比較}

\subsection{Upstart への切り替え}

\subsubsection{Sid での場合}

\subsubsection{Lenny での場合}

Squeeze へアップグレードするときに、


% =======================================================================
\dancersection{東京エリアDebian勉強会予約システムの構想}{上川 純一}
\index{よやくしすてむ@予約システム}
% =======================================================================

\subsection{背景}
\index{えんかいくん@宴会君}
\index{ATND}
\index{cotocoto}

東京エリアDebian勉強会では「えんかい君」を予約システムとして利用していま
した。えんかい君はシンプルなユーザインタフェースで認証もなく、全員のメー
ルアドレスと名前が閲覧でき、他人の登録を誰でも削除できるなど、利用者を信
頼したモデルになっていました。後で立ち上がった関西ではcotocotoを利用して
いました。cotocotoは DFSG の観点では non-free なサービスです。

「えんかい君」はYLUGなどでも利用されていましたが、不便でした。東京では、
「えんかい君」の制限を回避するため、課題の提出をメール経由でやっていまし
た。当初はフリーフォーマットのメールを \LaTeX 形式に上川がバッチで変換す
る形式をとっており、のちに \LaTeX のソースコードをメールで git
format-patch で送るという運用になっていました。ただ、Gitで課題提出をして
いても、マージが面倒という問題点がありました。

2009年12月の勉強会登録には実験的に atnd を利用しました。atnd はDFSG
non-free なサービスですが、最近流行している勉強会等の予約システムです。

DFSG 準拠のアプリケーションのほうが望ましいが、「えんかい君」ではうまく運
用できないということと、アプリケーション自体はシンプルな問題であることが
予想されたため、自前で勉強会予約システムを準備してみることにしました。

\subsection{実装目標}

Debian勉強会の予約システムでは何が必要でしょうか。

\begin{itemize}
 \item イベントの主催者が簡便に登録情報を設定することができること。
 \item イベントの主催者が事前課題を設定し、回答を簡単に収集することがで
       きること。
 \item イベントの主催者が簡単に参加人数を確認することができること。
 \item イベントの主催者が新規参加者の情報を迅速に確認できること。
 \item イベントの主催者が参加者に直接連絡がとれる手段があること。
 \item 参加者が簡単に事前課題もあわせて登録できること。
 \item 参加者がイベント参加をキャンセルする方法があること。
 \item 参加者が参加しているイベントを把握する方法があること。
\end{itemize}

他にもいろいろあるかもしれませんが、とりあえずこういうものを目標にしてやっ
てみました。

そして、DFSG Free であることが望ましいです。

\subsection{開発環境の準備}

\subsubsection{App Engine Python SDK の準備}

今回はウェブアプリケーションのフレームワークとして、Python 版の Google
App Engine を利用しました。
開発環境をDebian GNU/Linux sid 上で準備する方法を紹介します。

まず、Debian GNU/Linux sid の環境を用意します。

次に、Google App EngineのPython版の開発環境をダウンロードします。Google
App Engine のサイト
\footnote{\url{http://code.google.com/intl/ja/appengine/}}にいって最新の
SDKをダウンロードしてきます。

「Linux/その他のプラットフォーム」向けの
\url{google_appengine_1.3.1.zip}をダウンロードしてきました。

\begin{commandline}
# apt-get install unzip python　python-webtest python-yaml
$ wget http://googleappengine.googlecode.com/files/google_appengine_1.3.1.zip
$ unzip google_appengine_1.3.1.zip 
\end{commandline}
% $ -- for emacs

これでインストールは完了です。
Google App Engine のインストールディレクトリを \url{./google_appengine}, 
App Engine アプリケーションのソースコードのおいている場所を\url{./utils/gae}とします。
utils/gae ディレクトリにから \url{dev_appserver.py}を実行すれば、開発用
のウェブサーバが起動します。

\begin{commandline}
hoge@core2duo:appengine/utils/gae$ ../../google_appengine/dev_appserver.py .
INFO     2010-02-16 15:28:08,816 appengine_rpc.py:159] Server: appengine.google.com
Allow dev_appserver to check for updates on startup? (Y/n): n
dev_appserver will not check for updates on startup.  To change this setting, edit /home/hoge/.appcfg_nag
WARNING  2010-02-16 15:28:13,792 datastore_file_stub.py:623] Could not read datastore data from /tmp/dev_appserver.datastore
WARNING  2010-02-16 15:28:13,906 dev_appserver.py:3581] Could not initialize images API; you are likely missing the Python "PIL" module. ImportError: No module named _imaging
INFO     2010-02-16 15:28:13,914 dev_appserver_main.py:399] Running application debianmeeting on port 8080: http://localhost:8080
\end{commandline}


\subsubsection{テストの実行方法}

Django の通常のアプリケーションはテスト用の仕組みがあるようなのですが、
appengine にはないようです。ここでは、WebTest モジュールを利用して自動テ
ストコードを実装しています。

\begin{commandline}
$ PYTHONPATH=../../google_appengine:../../google_appengine/lib/django/ \
 python testSystem.py
\end{commandline}

\subsection{実装}
\subsubsection{認証の仕組み}

このアプリケーションでは Google App Engine を利用しています。ユーザ認証は
Google App Engine で標準で提供されるGoogleの認証を流用しています。パスワー
ドの管理やユーザのメールアドレスの管理などをフレームワークに一任することで管理を
簡単にしています。


\subsubsection{データベースの構造}

バックエンドのデータベースには、AppEngineのDatastoreを利用しています。
Event と、 Attendance と UserRealName というのを定義しています。

Event は主催者がイベントについて登録した情報を保持しています。イベント毎
に存在しています。

Attendance はユーザがイベントに登録したという情報を保持しています。
イベントに対して登録したユーザの数だけ存在します。

UserRealname はユーザの表示名前の情報を保持しています。
各ユーザ毎に存在します。

\begin{commandline}

class Event(db.Model):
    eventid = db.StringProperty()
    owner = db.UserProperty() # the creator is the owner
    owners_email = db.StringListProperty() # allow owner emails to be added if possible
    title = db.StringProperty()
    location = db.StringProperty(multiline=True)
    content = db.StringProperty(multiline=True)
    content_url = db.StringProperty()
    prework = db.StringProperty(multiline=True)
    event_date = db.StringProperty()
    timestamp = db.DateTimeProperty(auto_now_add=True)
    capacity = db.IntegerProperty() # the number of possible people attending the meeting

class Attendance(db.Model):
    eventid = db.StringProperty()
    user = db.UserProperty()
    user_realname = db.StringProperty() # keep a cache of last realname entry.
    prework = db.StringProperty(multiline=True) # obsolete, but used in initial version
    prework_text = db.TextProperty() # Used everywhere, populate from prework if available.
    attend = db.BooleanProperty()
    enkai_attend = db.BooleanProperty()
    timestamp = db.DateTimeProperty(auto_now_add=True)

class UserRealname(db.Model):
    """Backup of user realname configuration so that user doesn't have to reenter that information."""
    user = db.UserProperty()
    realname = db.StringProperty()
    timestamp = db.DateTimeProperty(auto_now_add=True)

\end{commandline}

\subsubsection{ソースコードの構造}

ソースコードは現在下記の構成です。
\begin{itemize}
 \item \url{debianmeeting.py}: どのページがどのコードを呼び出すのかとい
       う部分を管理しているコードです。あと、どこに入れるのか迷ったコー
       ドもここにあるかも。
 \item \url{admin_event.py}: 主催者のイベントの管理関連のコードです。
 \item \url{user_registration.py}: ユーザの登録関連のコードです。
 \item \url{webapp_generic.py}: とりあえず共通のロジックを定義しています。
       POST と GET を同じように扱うためのコードなどが入っています。
 \item \url{schema.py}: データストアのスキーマが定義されています。
 \item \url{send_notification.py}: メール送信とXMPP送信ロジックが記述さ
       れています。
 \item \url{testSystem.py}: ユニットテストです。
\end{itemize}

ソース内部からテンプレートファイルが参照されています。

\begin{itemize}
 \item \url{EditEvent.html}
 \item \url{PreworkLatex.txt}
 \item \url{RegisterEvent.txt}
 \item \url{Thanks.html}
 \item \url{TopPage.html}
 \item \url{UserCommitEventRegistration.txt}
 \item \url{UserEventRegistrationPage.html}
 \item \url{UserEventRegistrationPage_Simple.html}
 \item \url{ViewEventSummary.html}
\end{itemize}

\subsubsection{ウェブページの遷移}

ウェブページの遷移とソースコードの対応をみてみます。

\includegraphics[width=1\hsize]{image201001/debian-reservation-flow.eps}


\subsection{今後の展望}


とりあえずは動いています。今後、何が変わるべきか。今後どういう点が実装さ
れるべきか。パッチウェルカム。



%\printindex

\cleartooddpage

\vspace*{15cm}
\hrule
\vspace{2mm}
\includegraphics[width=2cm]{image200502/openlogo-nd.eps}
\noindent \Large \bf Debian 勉強会資料\\ \\
\noindent \normalfont \debmtgyear{}年\debmtgmonth{}月\debmtgdate{}日 \hspace{5mm}  初版第1刷発行\\
\noindent \normalfont 東京エリア Debian 勉強会 （編集・印刷・発行）\\
\hrule

\end{document}
